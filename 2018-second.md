|논문명 |SECOND:Sparsely Embedded Convolutional Detection |
| --- | --- |
| 저자\(소속\) | Yan Yan(=traveller59), Bo Li\(\) |
| 학회/년도 | 2018, [논문](https://www.mdpi.com/1424-8220/18/10/3337) |
| Citation ID / 키워드 | |
| 데이터셋(센서)/모델 | KITTI-3D Object Detection |
| 관련연구|Saprse ConvNet 아이디어 활용|
| 참고 | |
| 코드 |[깃허브](https://github.com/traveller59/second.pytorch)  |



|년도|1st 저자|논문명|코드|
|-|-|-|-|
|2014|Benjamin Graham|[Spatially-sparse convolutional neural networks](https://arxiv.org/abs/1409.6070)|[2013-2015](https://github.com/btgraham/SparseConvNet)|
|2017|Benjamin Graham|[Submanifold Sparse Convolutional Networks](https://arxiv.org/abs/1706.01307)|[SparseConvNet](https://github.com/facebookresearch/SparseConvNet)|
|2018|Benjamin Graham|[3D Semantic Segmentation with Submanifold Sparse Convolutional Networks](https://arxiv.org/abs/1711.10275)|~~[SparseConvNet(deprecated)](https://github.com/facebookresearch/SparseConvNet)~~,[spconv](https://github.com/traveller59/spconv)|
|2018|Bo Li|[SECOND:Sparsely Embedded Convolutional Detection](https://www.mdpi.com/1424-8220/18/10/3337)|[SECOND](https://github.com/traveller59/second.pytorch)|




# SECOND: Sparsely Embedded Convolutional Detection


Lidar는 여러 분야에 중요 하다. `LiDAR-based or RGB-D-based object detection is used in numerous applications, ranging from autonomous driving to robot vision. `

Voxel-based 3D convolutional networks는 Lidar데이터 에서 의미 있는 정보 수집시 사용 되어 왔다. `Voxel-based 3D convolutional networks have been used for some time to enhance the retention of information when processing point cloud LiDAR data.`

문제는 느린 성능과, 자세(=Orientation)추정 성능이다. `However, problems remain, including a slow inference speed and low orientation estimation performance. `

학습/테스트 속도를 올릴수 있는 sparse conv네트워크를 조사 하였다. `We therefore investigate an improved sparse convolution method for such networks, which significantly increases the speed of both training and inference. `

또한 새로운 자세 추정을 위한 angle LOSS와 데이터 증폭 기법을 제안 한다. `We also introduce a new form of angle loss regression to improve the orientation estimation performance and a new data augmentation approach that can enhance the convergence speed and performance. `

제안 기법은 빠른 성능을 보이면서 좋은 결과를 나타냈다. `The proposed network produces state-of-the-art results on the KITTI 3D object detection benchmarks while maintaining a fast inference speed.`


## 1. Introduction

State-of-the-art methods can achieve 
- an average precision (AP) of 90% of 2D car detection 
- but only an AP of 15% [7] for 3D image-based car detection.

최근 3D Detector 연구 트랜트는 이미지와 클라우드 데이터를 퓨전하여 많이 사용한다.  : `Many current 3D detectors use a fusion method that exploits both images and point cloud data.`
- Point cloud data are converted into a 2D bird’s eye view image [8] or are projected onto an image [9,10]. 
- Features are then extracted using a convolutional network, and a fusion process is applied to map the features between the image and other views. 

```
[8] Chen, X.; Ma, H.; Wan, J.; Li, B.; Xia, T. Multi-view 3D object detection network for autonomous driving. In Proceedings of the IEEE Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21–26 July 2017; Volume 1, p. 3. [Google Scholar]

[9] Ku, J.; Mozifian, M.; Lee, J.; Harakeh, A.; Waslander, S. Joint 3D Proposal Generation and Object Detection from View Aggregation. arXiv, 2017; arXiv:1712.02294. [Google Scholar]

[10] Du, X.; Ang Jr, M.H.; Karaman, S.; Rus, D. A general pipeline for 3D detection of vehicles. arXiv, 2018; arXiv:1803.00387. [Google Scholar]


```

In [11], 
- the point cloud data are initially filtered using bounding boxes generated by a 2D detector, 
- and a convolutional network is then used to directly process the points. 

```
[11] Qi, C.R.; Liu, W.; Wu, C.; Su, H.; Guibas, L.J. Frustum PointNets for 3D Object Detection from RGB-D Data. arXiv, 2017; arXiv:1711.08488. [Google Scholar]
```

In other methods, such as those of [12,13,14,15], 
- the point cloud data are assigned to volumetric grid cells via quantization, 
- and 3D CNNs are then applied.

```
[12] Wang, D.Z.; Posner, I. Voting for Voting in Online Point Cloud Object Detection. In Proceedings of the Robotics: Science and Systems, Rome, Italy, 13–17 July 2015; Volume 1. [Google Scholar]

[13] Engelcke, M.; Rao, D.; Wang, D.Z.; Tong, C.H.; Posner, I. Vote3deep: Fast object detection in 3D point clouds using efficient convolutional neural networks. In Proceedings of the 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 29 May–3 June 2017; pp. 1355–1361. [Google Scholar]

[14] Zhou, Y.; Tuzel, O. VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection. arXiv, 2017; arXiv:1711.06396. [Google Scholar]

[15] Li, B. 3D fully convolutional network for vehicle detection in point cloud. In Proceedings of the IEEE 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Vancouver, BC, Canada, 24–28 September 2017; pp. 1513–1518. [Google Scholar]

```

Recently, a new approach called VoxelNet [14] has been developed. 
- This approach combines raw point cloud feature extraction and voxel-based feature extraction in a single-stage end-to-end network. 
- It first groups point cloud data into voxels and then applies linear networks voxel by voxel before converting the voxels into dense 3D tensors to be used in a region proposal network (RPN) [16]. 
- 가장 최신 기술이지만, 속도가 느리다. `At present, this is a state-of-the-art approach. However, its computational cost makes it difficult to use for real-time applications. `


본 논문에서 제안 하는 SECOND를 이용하여 이런 문제를 해결 하고자 한다. `In this paper, we present a novel approach called SECOND (Sparsely Embedded CONvolutional Detection), which addresses these challenges in 3D convolution-based detection by maximizing the use of the rich 3D information present in point cloud data. `

This method incorporates several improvements to the existing convolutional network architecture. 

### 1.1 첫번째 장점 : Spatially sparse convolutional networks

Spatially sparse convolutional networks are introduced for LiDAR-based detection and are used to extract information from the z-axis before the 3D data are downsampled to something akin to 2D image data. 
- We also use a GPU-based rule generation algorithm for sparse convolution to increase the speed. 

제안 하는 Sparse conv네트워크는 기존의 Dense conv네트워크에 비해서 속도가 빠르다. `In comparison to a dense convolution network, our sparse-convolution-based detector achieves a factor-of-4 speed enhancement during training on the KITTI dataset and a factor-of-3 improvement in the speed of inference. `


As a further test, we have designed a small model for real-time detection that has a run time of approximately 0.025 s on a GTX 1080 Ti GPU, with only a slight loss of performance.

> 제출 시점에 큰 모델로는 20fps,  작은 모델은 40fps 속도로 KITI 3D Detection을 수행 ㅏ였다. 

### 1.2 두번째 장점 : Data augmentation 

Another advantage of using point cloud data is that it is very easy to scale, rotate and move objects by applying direct transformations to specified points on those objects. 

SECOND incorporates a novel form of data augmentation based on this capability. 

A ground-truth database is generated that contains the attributes of objects and the associated point cloud data. 

Objects sampled from this database are then introduced into the point clouds during training. 

This approach can greatly increase the convergence speed and the final performance of our network.

### 1.3 세번째 장점 : angle loss regression

In addition to the above, we also introduce a novel angle loss regression approach to solve the problem of the large loss generated when the difference in orientation between the ground truth and the prediction is equal to π, which yields a bounding box identical to the true bounding box. 

The performance of this angle regression approach surpasses that of any current method we know about, including the orientation vector regression function available in AVOD [9]. 

We also introduce an auxiliary direction classifier to recognize the directions of objects.


### 1.4 본 논문의 기여 

The key contributions of our work are as follows:

- We apply sparse convolution in LiDAR-based object detection, thereby greatly increasing the speeds of training and inference.
- We propose an improved method of sparse convolution that allows it to run faster.
- We propose a novel angle loss regression approach that demonstrates better orientation regression performance than other methods do.
- We introduce a novel data augmentation method for LiDAR-only learning problems that greatly increases the convergence speed and performance.


## 2. Related Work

Below, we briefly review existing works on 3D object detection based on point cloud data and images.


### 2.1. Front-View- and Image-Based Methods

Methods using 2D representations of RGB-D data can be divided into two classes: 
- those based on a bird’s eye view (BEV) 
- those based on a front view. 

In typical image-based methods [5], 2D bounding boxes, class semantics and instance semantics are generated first, and then hand-crafted approaches are used to generate feature maps. 

Another method [17] uses a CNN to estimate 3D bounding boxes from images and a specially designed discrete-continuous CNN to estimate the orientations of objects. 

Methods using LiDAR [18] involve the conversion of point clouds into front-view 2D maps and the application of 2D detectors to localize objects in the front-view images. 

These methods have been shown to perform poorly for both BEV detection and 3D detection compared to other methods.


### 2.2. Bird’s-Eye-View-Based Methods

MV3D [8] is the first method to convert point cloud data into a BEV representation. 
- In this method, point cloud data are converted into several slices to obtain height maps, 
- and these height maps are then concatenated with the intensity map and density map to obtain multichannel features. 

ComplexYOLO [19] 
- uses a YOLO (You Only Look Once) [20] network and a complex angle encoding approach to increase speed and orientation performance, 
- but it uses fixed heights and z-locations in the predicted 3D bounding boxes. 


In [21], 
- a fast single-stage proposal-free detector is designed that makes use of specific height-encoded BEV input. 


위 방법들의 단점은 BEV를 생성하면서 버려지는 정보(point)들이 많다. `A key problem with all of these approaches, however, is that many data points are dropped when generating a BEV map, resulting in a considerable loss of information on the vertical axis. `
- 이로 인해 3D BBox생성에 문제가 된다. `This information loss severely impacts the performance of these methods in 3D bounding box regression.`


### 2.3. 3D-Based Methods















