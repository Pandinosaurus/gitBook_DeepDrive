|논문명 |SECOND:Sparsely Embedded Convolutional Detection |
| --- | --- |
| 저자\(소속\) | Yan Yan(=traveller59), Bo Li\(\) |
| 학회/년도 | 2018, [논문](https://www.mdpi.com/1424-8220/18/10/3337) |
| Citation ID / 키워드 | |
| 데이터셋(센서)/모델 | KITTI-3D Object Detection |
| 관련연구|Saprse ConvNet 아이디어 활용|
| 참고 | |
| 코드 |[깃허브](https://github.com/traveller59/second.pytorch)  |



|년도|1st 저자|논문명|코드|
|-|-|-|-|
|2014|Benjamin Graham|[Spatially-sparse convolutional neural networks](https://arxiv.org/abs/1409.6070)|[2013-2015](https://github.com/btgraham/SparseConvNet)|
|2017|Benjamin Graham|[Submanifold Sparse Convolutional Networks](https://arxiv.org/abs/1706.01307)|[SparseConvNet](https://github.com/facebookresearch/SparseConvNet)|
|2018|Benjamin Graham|[3D Semantic Segmentation with Submanifold Sparse Convolutional Networks](https://arxiv.org/abs/1711.10275)|~~[SparseConvNet(deprecated)](https://github.com/facebookresearch/SparseConvNet)~~,[spconv](https://github.com/traveller59/spconv)|
|2018|Bo Li|[SECOND:Sparsely Embedded Convolutional Detection](https://www.mdpi.com/1424-8220/18/10/3337)|[SECOND](https://github.com/traveller59/second.pytorch)|




# SECOND: Sparsely Embedded Convolutional Detection


Lidar는 여러 분야에 중요 하다. `LiDAR-based or RGB-D-based object detection is used in numerous applications, ranging from autonomous driving to robot vision. `

Voxel-based 3D convolutional networks는 Lidar데이터 에서 의미 있는 정보 수집시 사용 되어 왔다. `Voxel-based 3D convolutional networks have been used for some time to enhance the retention of information when processing point cloud LiDAR data.`

문제는 느린 성능과, 자세(=Orientation)추정 성능이다. `However, problems remain, including a slow inference speed and low orientation estimation performance. `

학습/테스트 속도를 올릴수 있는 sparse conv네트워크를 조사 하였다. `We therefore investigate an improved sparse convolution method for such networks, which significantly increases the speed of both training and inference. `

또한 새로운 자세 추정을 위한 angle LOSS와 데이터 증폭 기법을 제안 한다. `We also introduce a new form of angle loss regression to improve the orientation estimation performance and a new data augmentation approach that can enhance the convergence speed and performance. `

제안 기법은 빠른 성능을 보이면서 좋은 결과를 나타냈다. `The proposed network produces state-of-the-art results on the KITTI 3D object detection benchmarks while maintaining a fast inference speed.`


## 1. Introduction

State-of-the-art methods can achieve 
- an average precision (AP) of 90% of 2D car detection 
- but only an AP of 15% [7] for 3D image-based car detection.

최근 3D Detector 연구 트랜트는 이미지와 클라우드 데이터를 퓨전하여 많이 사용한다.  : `Many current 3D detectors use a fusion method that exploits both images and point cloud data.`
- Point cloud data are converted into a 2D bird’s eye view image [8] or are projected onto an image [9,10]. 
- Features are then extracted using a convolutional network, and a fusion process is applied to map the features between the image and other views. 


In [11], 
- the point cloud data are initially filtered using bounding boxes generated by a 2D detector, 
- and a convolutional network is then used to directly process the points. 

In other methods, such as those of [12,13,14,15], 
- the point cloud data are assigned to volumetric grid cells via quantization, 
- and 3D CNNs are then applied.

Recently, a new approach called VoxelNet [14] has been developed. 
- This approach combines raw point cloud feature extraction and voxel-based feature extraction in a single-stage end-to-end network. 
- It first groups point cloud data into voxels and then applies linear networks voxel by voxel before converting the voxels into dense 3D tensors to be used in a region proposal network (RPN) [16]. 
- 가장 최신 기술이지만, 속도가 느리다. `At present, this is a state-of-the-art approach. However, its computational cost makes it difficult to use for real-time applications. `


본 논문에서 제안 하는 SECOND를 이용하여 이런 문제를 해결 하고자 한다. `In this paper, we present a novel approach called SECOND (Sparsely Embedded CONvolutional Detection), which addresses these challenges in 3D convolution-based detection by maximizing the use of the rich 3D information present in point cloud data. `

This method incorporates several improvements to the existing convolutional network architecture. 

### 1.1 첫번째 장점 : Spatially sparse convolutional networks

Spatially sparse convolutional networks are introduced for LiDAR-based detection and are used to extract information from the z-axis before the 3D data are downsampled to something akin to 2D image data. 
- We also use a GPU-based rule generation algorithm for sparse convolution to increase the speed. 

제안 하는 Sparse conv네트워크는 기존의 Dense conv네트워크에 비해서 속도가 빠르다. `In comparison to a dense convolution network, our sparse-convolution-based detector achieves a factor-of-4 speed enhancement during training on the KITTI dataset and a factor-of-3 improvement in the speed of inference. `


As a further test, we have designed a small model for real-time detection that has a run time of approximately 0.025 s on a GTX 1080 Ti GPU, with only a slight loss of performance.

> 제출 시점에 큰 모델로는 20fps,  작은 모델은 40fps 속도로 KITI 3D Detection을 수행 ㅏ였다. 

### 1.2 두번째 장점 : Data augmentation 

Another advantage of using point cloud data is that it is very easy to scale, rotate and move objects by applying direct transformations to specified points on those objects. 

SECOND incorporates a novel form of data augmentation based on this capability. 

A ground-truth database is generated that contains the attributes of objects and the associated point cloud data. 

Objects sampled from this database are then introduced into the point clouds during training. 

This approach can greatly increase the convergence speed and the final performance of our network.

### 1.3 세번째 장점 : angle loss regression

In addition to the above, we also introduce a novel angle loss regression approach to solve the problem of the large loss generated when the difference in orientation between the ground truth and the prediction is equal to π, which yields a bounding box identical to the true bounding box. 

The performance of this angle regression approach surpasses that of any current method we know about, including the orientation vector regression function available in AVOD [9]. 

We also introduce an auxiliary direction classifier to recognize the directions of objects.


### 1.4 본 논문의 기여 

The key contributions of our work are as follows:

- We apply sparse convolution in LiDAR-based object detection, thereby greatly increasing the speeds of training and inference.
- We propose an improved method of sparse convolution that allows it to run faster.
- We propose a novel angle loss regression approach that demonstrates better orientation regression performance than other methods do.
- We introduce a novel data augmentation method for LiDAR-only learning problems that greatly increases the convergence speed and performance.
