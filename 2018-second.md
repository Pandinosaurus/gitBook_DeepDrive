|논문명 |SECOND:Sparsely Embedded Convolutional Detection |
| --- | --- |
| 저자\(소속\) | Yan Yan(=traveller59), Bo Li\(\) |
| 학회/년도 | 2018, [논문](https://www.mdpi.com/1424-8220/18/10/3337) |
| Citation ID / 키워드 | |
| 데이터셋(센서)/모델 | KITTI-3D Object Detection |
| 관련연구|Saprse ConvNet 아이디어 활용|
| 참고 | |
| 코드 |[깃허브](https://github.com/traveller59/second.pytorch)  |



|년도|1st 저자|논문명|코드|
|-|-|-|-|
|2014|Benjamin Graham|[Spatially-sparse convolutional neural networks](https://arxiv.org/abs/1409.6070)|[2013-2015](https://github.com/btgraham/SparseConvNet)|
|2017|Benjamin Graham|[Submanifold Sparse Convolutional Networks](https://arxiv.org/abs/1706.01307)|[SparseConvNet](https://github.com/facebookresearch/SparseConvNet)|
|2018|Benjamin Graham|[3D Semantic Segmentation with Submanifold Sparse Convolutional Networks](https://arxiv.org/abs/1711.10275)|~~[SparseConvNet(deprecated)](https://github.com/facebookresearch/SparseConvNet)~~,[spconv](https://github.com/traveller59/spconv)|
|2018|Bo Li|[SECOND:Sparsely Embedded Convolutional Detection](https://www.mdpi.com/1424-8220/18/10/3337)|[SECOND](https://github.com/traveller59/second.pytorch)|




# SECOND: Sparsely Embedded Convolutional Detection


Lidar는 여러 분야에 중요 하다. `LiDAR-based or RGB-D-based object detection is used in numerous applications, ranging from autonomous driving to robot vision. `

Voxel-based 3D convolutional networks는 Lidar데이터 에서 의미 있는 정보 수집시 사용 되어 왔다. `Voxel-based 3D convolutional networks have been used for some time to enhance the retention of information when processing point cloud LiDAR data.`

문제는 느린 성능과, 자세(=Orientation)추정 성능이다. `However, problems remain, including a slow inference speed and low orientation estimation performance. `

학습/테스트 속도를 올릴수 있는 sparse conv네트워크를 조사 하였다. `We therefore investigate an improved sparse convolution method for such networks, which significantly increases the speed of both training and inference. `

또한 새로운 자세 추정을 위한 angle LOSS와 데이터 증폭 기법을 제안 한다. `We also introduce a new form of angle loss regression to improve the orientation estimation performance and a new data augmentation approach that can enhance the convergence speed and performance. `

제안 기법은 빠른 성능을 보이면서 좋은 결과를 나타냈다. `The proposed network produces state-of-the-art results on the KITTI 3D object detection benchmarks while maintaining a fast inference speed.`


## 1. Introduction

State-of-the-art methods can achieve 
- an average precision (AP) of 90% of 2D car detection 
- but only an AP of 15% [7] for 3D image-based car detection.

최근 3D Detector 연구 트랜트는 이미지와 클라우드 데이터를 퓨전하여 많이 사용한다.  : `Many current 3D detectors use a fusion method that exploits both images and point cloud data.`
- Point cloud data are converted into a 2D bird’s eye view image [8] or are projected onto an image [9,10]. 
- Features are then extracted using a convolutional network, and a fusion process is applied to map the features between the image and other views. 


In [11], 
- the point cloud data are initially filtered using bounding boxes generated by a 2D detector, 
- and a convolutional network is then used to directly process the points. 

In other methods, such as those of [12,13,14,15], 
- the point cloud data are assigned to volumetric grid cells via quantization, 
- and 3D CNNs are then applied.

Recently, a new approach called VoxelNet [14] has been developed. 
- This approach combines raw point cloud feature extraction and voxel-based feature extraction in a single-stage end-to-end network. 
- It first groups point cloud data into voxels and then applies linear networks voxel by voxel before converting the voxels into dense 3D tensors to be used in a region proposal network (RPN) [16]. 
- 가장 최신 기술이지만, 속도가 느리다. `At present, this is a state-of-the-art approach. However, its computational cost makes it difficult to use for real-time applications. `


In this paper, we present a novel approach called SECOND (Sparsely Embedded CONvolutional Detection), which addresses these challenges in 3D convolution-based detection by maximizing the use of the rich 3D information present in point cloud data. This method incorporates several improvements to the existing convolutional network architecture. Spatially sparse convolutional networks are introduced for LiDAR-based detection and are used to extract information from the z-axis before the 3D data are downsampled to something akin to 2D image data. We also use a GPU (Graphics Processing Unit)-based rule generation algorithm for sparse convolution to increase the speed. In comparison to a dense convolution network, our sparse-convolution-based detector achieves a factor-of-4 speed enhancement during training on the KITTI dataset and a factor-of-3 improvement in the speed of inference. As a further test, we have designed a small model for real-time detection that has a run time of approximately 0.025 s on a GTX 1080 Ti GPU, with only a slight loss of performance.







