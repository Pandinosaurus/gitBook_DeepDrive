# Summary

## Introduction/Survy

* [ReadME](README.md)
* [List\_of\_DeepDrive](-toread-deepdrive-.md)
* [List\_of\_DeepDrive2](listof-deepdrive2.md)
* [----- Pointcloud based -----](-pointcloud-based-.md)

## Survey

* [Paper\_2013\_Survey\_Vehicle Detection \(0%\)](paper2013-survey-vehicle-detection.md)
* [Paper\_2016\_Sementic\_Fusion](paper2016-sementic-fusion.md)
* [Paper\_2017\_Guide\_Segmetation\_AutomatedDriving \(100%\)](paper2017-segmetation-automateddriving.md)
* [Paper\_2017\_Sruvey\_3D data\(100%\)](paper2017-sruvey-3d-data.md)
* [Paper\_2017\_Survey\_CV4Vehicle \(50%\)](paper2017-survey.md)
* [Paper\_2017\_Overview of Services \(50%\)](paper2017-overview-of-services.md)
* [Paper\_2018\_Survey\_Self-Driving Cars \(15%\)](paper2018-survey-self-driving-cars.md)
* [Paper\_2018\_A Survey of Clustering With Deep Learning](survey/Deep_clustering.md)
* [Paper\_2018\_Clustering with Deep Learning](survey/Clustering-with-Deep-Learning.md)

## 3D OverView

* [Intro\_3D CloudPoint](intro3d-cloudpoint.md)
* [Paper\_2010\_Pedestrian Detection and Tracking Using Three-dimensional LADAR Data](paper2010-pedestrian-detection-and-tracking-using-three-dimensional-ladar-data.md)
* [Paper\_2011\_Pedestrian Recognition Using High-definition LIDAR](paper2011pedestrian-recognition-using-high-definition-lidar.md)
* [Paper\_2013\_Survey\_2D\_3DShape Descriptor \(30%\)](paper2016-deep-learning-representation.md)
* [Paper\_2015\_MVCNN \(70%\)](paper2015-mvcnn.md)
* [Paper\_2015\_DeepPano \(70%\)](paper2015-deeppano.md)
* [Paper\_2015\_3D\_ShapeNet \(50%\)](paper2015-3d-shapenet.md)
* [Paper\_2015\_VoxNet \(70%\)](papervoxnet.md)
* [Paper\_2016\_V\_M CNNs \(70%\)](paper2016-volumetric-multiview-cnns.md)
* [Paper\_2016\_pMVCNN \(30%\)](paper2016-pairwisemvcnn.md)
* [Paper\_2016\_VeloFCN\_Bo Li \(70%\)](paper2016-velofcn4vd.md)
* [Paper\_2016\_3D GAN](paper2016-3d-gan.md)
* [Paper\_2016\_FPNN](paper2016-fpnn.md)
* [Paper\_2016\_PointNet \(50%\)](paper2016-pointnet.md)
  * [PointNet-pytorch](paper2016-pointnet/pointnet-pytorch.md)
* [Paper\_2016\_PointNet3D \(50%\)](paper2016-pointnet3d.md)
* [Paper\_2016\_FCN4VD\_Bo Li  \(30%\)](paper3d-cnn.md)
* [Paper\_2017\_Depth\_Clustering](paper2017-depthclustering.md)
* [Paper\_2017\_Vote3Deep \(50%\)](papervote3deep.md)
* [Paper-2017-Multi-View 3D](paper2017-mv3d.md)
  * [mv3d-implementation](paper2017-mv3d/mv3d-implementation.md)
* [Paper\_2017\_SegCloud](paper2017-segcloud.md)
* [Paper\_2017\_VoxelNet](paper2017-voxelnet.md)
  * [VoxelNet-tensorflow](paper2017-voxelnet/voxelnet-tensorflow.md)
* [Paper\_2017\_LoDNN\_Road Detection \(10%\)](paper2017-lodnnroad-detection.md)
* [Paper\_2017\_SqueezeSeg](paper2017-squeezeseg.md)
* [Tutorial\_2017\_CVPR\_3D Deeplearning](tutorial2017-cvpr-3d-deeplearning.md)
* [Paper\_2018-SECOND](paper2018-second.md)
  * [SECOND-pytorch](2018-second/second-pytorch.md)
* [Code\_2018\_DenseLidarNet](code2018-DenseLidarNet.md)
* [Paper\_2019\_Pseudo-LiDAR from Visual Depth Estimation](paper2019-Pseudo-LiDAR.md)

## 2D + Time \(Video\)

* [Paper\_2017\_DeepFeatureFlow \(0%\)](paper2017-deepfeatureflow.md)

## 참고

* [ref00\_Terms](ref00terms.md)
* [ref01\_Hardware](ref01hardware.md)
* [ref02\_Metrics](ref02metrics.md)
* [ref03\_Tracklet](ref03tracklet.md)
* ref04\_non-maxima suppression \(NMS\)
* [ref05-Read\_RGBD](pointcloud-data/readrgbd.md)
* [Simulator\_CARLA](simulatorcarla.md)

## Out of Scope

* [Papers\_OccupancyGridFusion](papersoccupancygridfusion.md)
* [Paper\_2016\_MSF-OG \(5%\)](paper2016-msf-og.md)
* [----- Octree based -----](-octree-based-.md)
* [Paper\_2017\_OctNet \(30%\)](paper2017-octnet.md)
* [Paper\_2016\_3D-R2N2](paper2016-3d-r2n2.md)
* [----- 3D Feature based -----](-feature-based-.md)
* [Paper\_2015\_DeepSD \(70%\)](paper2016-deep-learning-representation/paper2015-3d-deep-shape-descriptor.md)
* [Paper\_2015\_DL Representation ](paper2016-deep-learning-representation/paper2015-dl-representation.md)
* [Paper\_2015\_3DMesh\_Laveling](paper2016-deep-learning-representation/paper2015-3dmesh-laveling.md)
* [Paper\_2014\_AE3D shape Retrieval \(30%\)](paper2014-ae3d-shape-retrieval.md)

## Project

* [Project\_2017\_Berkeley](project2017-berkeley.md)
* [Project\_2017\_iPRoBe Lab](project2017-iprobe-lab.md)
* [Project\_Autoware](projectautoware.md)
* [Project\_DiDi Competition](projectdidi-competition.md)
  * [Didi\_Getting\_Started](projectdidi-competition/didigetting-started.md)
  * [Didi\_Solution\_hengck23](projectdidi-competition/didisolution-hengck23.md)
  * [Didi\_Solution\_OmgTeam](projectdidi-competition/didisolution-omgteam.md)
  * [Didi\_Solution\_Timelaps](projectdidi-competition/didisolution-timelaps.md)
  * [Didi\_ref\_3D DataHandling](projectdidi-competition/didiref-3d-datahandling.md)
  * [Didi\_ref\_visualization](projectdidi-competition/didiref-visualization.md)

## LowLevel CV

* [List\_Scene Flow](listscene-flow.md)
* [Intro\_Scene Flow](introscene-flow.md)
* [Paper\_2014\_\[M\] DMP-MSnet \(20%\)](paper2014-depthmap-prediction.md)
* [Paper\_2015\_\[M\] Depth\_Monocular](paper2015-depth-monocular.md)
* [Paper\_2017\_\[M\] UnsuperviseMD \(30%\)](paper2016-monocular-depth.md)
* [Paper\_2017\_\[M\] Semi\_MDE \(0%\)](paper2017-semi-mde.md)
* [Paper\_2017\_\[M\] Domain Independent MDE  \(30%\)](paper2017-domain-independent-mde.md)
* [Paper\_2015\_FlowNet1 \(10%\)](paper2015-flownet1.md)
* [Paper\_2017\_FlowNet2](paper2017-flownet2.md)
* [Paper\_2015\_\[S\]DispNet \(30%\)](paper2015-dispnet.md)
* [Paper\_2016\_\[S\]DL4SM \(30%\)](paper2016-dl4sm.md)
* [Paper\_2016\_\[S\]StereoFusion \(0%\)](paper2016-stereofusion.md)

## 2D CNN

* [Paper\_2016\_MultiNet \(0%\)](paper2016-multinet.md)
* [Paper\_2017\_SqueezeDet \(50%\)](paper2016-squeezedet.md)
* [Paper\_2016\_SegNet](paper2016-segnet.md)

## 2D Monocular Vision

* [----- Monocular Vision -----](-monocular-vision-.md)
* [Intro\_MonocularVision](introback-projection.md)
* [Papers\_국내 논문\_단일카메라 \(100%\)](paperdepth-from-single-image/paper2015-b2e8-c77c-ce74-ba54-b77c-2-c7a5-c758-c774-bbf8-c9c0.md)
  * [Report\_2017\_Study\_Monocular \(70%\)](report2017-monocular-3-cnnmethods.md)
  * [Paper\_2016\_Unify monocular detectors \(5%\)](paper2017-unify-monocular-detectors.md)
* [Paper\_2016\_Mono3D2016 \(70%\)](papermonocular-3d.md)
* [Paper\_2017\_Deep3DBox \(15%\)](paper2017-3d-bbox.md)
* [Paper\_2017\_J-MOD \(30%\)](paper2017-j-mod.md)

## 2D Stereo Vision

* [----- Stereo Vision -----](-stereo-vision-.md)
* [Intro\_StereoVision](introstereovision.md)
  * [Paper\_2014\_Know\_limit\_stereo](paper2014-know-limit-stereo.md)
* [Paper\_2017\_3DOP\_X Chen \(70%\)](paper2017-3d-object-proposals.md)

